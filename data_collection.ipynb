{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import magic\n",
    "import pefile\n",
    "import csv\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Variables\n",
    "path = '/home/dev/data/pe-machine-learning-dataset/samples/'\n",
    "files = list(os.listdir(path))\n",
    "if os.path.isfile('samples.csv'):\n",
    "    os.remove('samples.csv')\n",
    "#output = open('samples.csv', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class object to hold all the data in memory. \n",
    "class sample():\n",
    "    def __init__(self, index, label):\n",
    "        self.index = index\n",
    "        self.label = label\n",
    "\n",
    "        # Magic header parser\n",
    "        self.file_type = \"\"\n",
    "        \n",
    "        # Size of the file\n",
    "        self.file_size = 0\n",
    "        \n",
    "        # Entropy of the file.\n",
    "        self.file_entropy = 0\n",
    "\n",
    "        ## PE Info \n",
    "\n",
    "        # IAT\n",
    "        self.imports = []\n",
    "        # EAT\n",
    "        self.exports = []\n",
    "\n",
    "        # Image size according to Optional Header\n",
    "        self.size_of_image = 0\n",
    "\n",
    "        # Size of code\n",
    "        self.size_of_code = 0\n",
    "\n",
    "        # Number of sections\n",
    "        self.number_of_sections = 0\n",
    "\n",
    "        # Heap and Stack\n",
    "        self.size_of_stack_reserve = 0\n",
    "        self.size_of_stack_commit = 0\n",
    "        self.size_of_heap_reserve = 0\n",
    "        self.size_of_heap_commit = 0\n",
    "\n",
    "        # Sections\n",
    "        self.sections = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of sample classes. \n",
    "samples = {}\n",
    "\n",
    "# Read Sample.csv\n",
    "with open('/home/dev/data/pe-machine-learning-dataset/samples.csv') as f:\n",
    "    for line in f:\n",
    "        try:\n",
    "            l = line.split(',')\n",
    "            s = sample(int(l[0].strip('\"')), 1 if 'Blacklist' in l[6] else 0)\n",
    "            samples[str(s.index)] = s\n",
    "        except:\n",
    "            continue # First like breaks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse PE function and add to the \n",
    "# sample object. \n",
    "def parse_pe(sample, filepath):\n",
    "    try:\n",
    "        pe =  pefile.PE(filepath)\n",
    "        try:\n",
    "            for entry in pe.DIRECTORY_ENTRY_IMPORT:\n",
    "                for imp in entry.imports:\n",
    "                    sample.imports.append(imp.name.decode('utf-8'))\n",
    "        except: \n",
    "            pass    \n",
    "        try:\n",
    "            for entry in pe.DIRECTORY_ENTRY_EXPORT.symbols:\n",
    "                sample.imports.append(entry.name)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        sample.number_of_sections = pe.FILE_HEADER.NumberOfSections\n",
    "        sample.size_of_code = pe.OPTIONAL_HEADER.SizeOfCode\n",
    "        sample.size_of_image = pe.OPTIONAL_HEADER.SizeOfImage\n",
    "\n",
    "        sample.size_of_stack_reserve = pe.OPTIONAL_HEADER.SizeOfStackReserve\n",
    "        sample.size_of_stack_commit = pe.OPTIONAL_HEADER.SizeOfStackCommit\n",
    "        sample.size_of_heap_reserve = pe.OPTIONAL_HEADER.SizeOfHeapReserve\n",
    "        sample.size_of_heap_commit = pe.OPTIONAL_HEADER.SizeOfHeapCommit\n",
    "\n",
    "        for section in pe.sections:\n",
    "            try:\n",
    "                sample.sections.append([\n",
    "                    section.Name.decode('utf-8'),\n",
    "                    section.SizeOfRawData,\n",
    "                    section.Misc_VirtualSize,\n",
    "                    1 if section.Characteristics & 0x00000020 > 0 else 0, # Contains code\n",
    "                    1 if section.Characteristics & 0x20000000 > 0 else 0, # Executable\n",
    "                    1 if section.Characteristics & 0x80000000 > 0 else 0, # Writable\n",
    "                ])\n",
    "            except:\n",
    "                sample.sections.append([\n",
    "                    section.Name,\n",
    "                    section.SizeOfRawData,\n",
    "                    section.Misc_VirtualSize,\n",
    "                    1 if section.Characteristics & 0x00000020 > 0 else 0, # Contains code\n",
    "                    1 if section.Characteristics & 0x20000000 > 0 else 0, # Executable\n",
    "                    1 if section.Characteristics & 0x80000000 > 0 else 0, # Writable\n",
    "                ])\n",
    "    except:\n",
    "        return    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Shannon Entropy of a File\n",
    "def entropy(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        byteArr = list(f.read())\n",
    "    fileSize = len(byteArr)\n",
    "    freqList = []\n",
    "    for b in range(256):\n",
    "        ctr = 0\n",
    "        for byte in byteArr:\n",
    "            if byte == b:\n",
    "                ctr += 1\n",
    "        freqList.append(float(ctr) / fileSize)\n",
    "    \n",
    "    ent = 0.0\n",
    "    for freq in freqList:\n",
    "        if freq > 0:\n",
    "            ent =  ent + freq * math.log(freq,2)\n",
    "    return -ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('samples.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\n",
    "        'index',\n",
    "        'label',\n",
    "        'file_type',\n",
    "        'file_size',\n",
    "        'file_entropy',\n",
    "        'imports',\n",
    "        'exports',\n",
    "        'size_of_image',\n",
    "        'size_of_code',\n",
    "        'size_of_stack_reserve',\n",
    "        'size_of_stack_commit',\n",
    "        'size_of_heap_reserve',\n",
    "        'size_of_heap_commit',\n",
    "        'number_of_sections',\n",
    "        'sections',        \n",
    "    ])\n",
    "    \n",
    "    for f in files:\n",
    "        samples[f].file_type = magic.from_file(path+f)\n",
    "        samples[f].file_size = os.stat(path+f).st_size\n",
    "\n",
    "        parse_pe(samples[f], path+f)\n",
    "        samples[f].file_entropy = entropy(path+f)\n",
    "    \n",
    "        writer.writerow([\n",
    "            samples[f].index,\n",
    "            samples[f].label,\n",
    "            samples[f].file_type,\n",
    "            samples[f].file_size,\n",
    "            samples[f].file_entropy,\n",
    "            samples[f].imports,\n",
    "            samples[f].exports,\n",
    "            samples[f].size_of_image,\n",
    "            samples[f].size_of_code,\n",
    "            samples[f].size_of_stack_reserve,\n",
    "            samples[f].size_of_stack_commit,\n",
    "            samples[f].size_of_heap_reserve,\n",
    "            samples[f].size_of_heap_commit,\n",
    "            samples[f].number_of_sections,\n",
    "            samples[f].sections,\n",
    "        ])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
