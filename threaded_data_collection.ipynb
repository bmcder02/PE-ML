{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import magic\n",
    "import pefile\n",
    "import csv\n",
    "import math\n",
    "from time import sleep\n",
    "\n",
    "from queue import Queue\n",
    "from threading import Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Variables\n",
    "path = '/home/dev/data/pe-machine-learning-dataset/samples/'\n",
    "files = list(os.listdir(path))\n",
    "if os.path.isfile('samples.csv'):\n",
    "    os.remove('samples.csv')\n",
    "\n",
    "numThreads = 10\n",
    "sampleQueue = Queue()\n",
    "writeQueue = Queue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201550"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Sample.csv\n",
    "with open('/home/dev/data/pe-machine-learning-dataset/samples.csv') as f:\n",
    "    for line in f:\n",
    "        try:\n",
    "            # Split the csv, and keep the filename (index) and a binary label\n",
    "            l = line.split(',')\n",
    "            #s = sample(int(l[0].strip('\"')), 1 if 'Blacklist' in l[6] else 0)\n",
    "            #samples[str(s.index)] = s\n",
    "            sampleQueue.put([l[0].strip('\"'), 1 if 'Blacklist' in l[6] else 0])\n",
    "        except:\n",
    "            continue # First like breaks\n",
    "\n",
    "\n",
    "sampleQueue.qsize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define what each thread will do. \n",
    "def ThreadJob(sampleQueue, writeQueue):\n",
    "    while not sampleQueue.empty():\n",
    "        sample = sampleQueue.get()\n",
    "        imports, \\\n",
    "        exports, \\\n",
    "        NumberOfSections, \\\n",
    "        SizeOfCode, \\\n",
    "        SizeOfImage, \\\n",
    "        SizeOfStackReserve, \\\n",
    "        SizeOfStackCommit, \\\n",
    "        SizeOfHeapReserve, \\\n",
    "        SizeOfHeapCommit, \\\n",
    "        sections = parse_pe(path+sample[0])\n",
    "\n",
    "        writeQueue.put([\n",
    "            int(sample[0]),\n",
    "            sample[1],\n",
    "            magic.from_file(path+sample[0]),\n",
    "            os.stat(path+sample[0]).st_size,\n",
    "            entropy(path+sample[0]),\n",
    "            imports,\n",
    "            exports,\n",
    "            SizeOfCode,\n",
    "            SizeOfImage,\n",
    "            SizeOfStackReserve,\n",
    "            SizeOfStackCommit,\n",
    "            SizeOfHeapReserve,\n",
    "            SizeOfHeapCommit,\n",
    "            NumberOfSections,\n",
    "            sections\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse PE function and add to the \n",
    "# sample object. \n",
    "def parse_pe(filepath):\n",
    "    try:\n",
    "        pe =  pefile.PE(filepath)\n",
    "        imports = []\n",
    "        exports = []\n",
    "        try:\n",
    "            for entry in pe.DIRECTORY_ENTRY_IMPORT:\n",
    "                for imp in entry.imports:\n",
    "                    imports.append(imp.name.decode('utf-8'))\n",
    "        except: \n",
    "            pass    \n",
    "        try:\n",
    "            for entry in pe.DIRECTORY_ENTRY_EXPORT.symbols:\n",
    "                imports.append(entry.name)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        sections = []\n",
    "        for section in pe.sections:\n",
    "            try:\n",
    "                sections.append([\n",
    "                    section.Name.decode('utf-8'),\n",
    "                    section.SizeOfRawData,\n",
    "                    section.Misc_VirtualSize,\n",
    "                    1 if section.Characteristics & 0x00000020 > 0 else 0, # Contains code\n",
    "                    1 if section.Characteristics & 0x20000000 > 0 else 0, # Executable\n",
    "                    1 if section.Characteristics & 0x80000000 > 0 else 0, # Writable\n",
    "                ])\n",
    "            except:\n",
    "                sections.append([\n",
    "                    section.Name,\n",
    "                    section.SizeOfRawData,\n",
    "                    section.Misc_VirtualSize,\n",
    "                    1 if section.Characteristics & 0x00000020 > 0 else 0, # Contains code\n",
    "                    1 if section.Characteristics & 0x20000000 > 0 else 0, # Executable\n",
    "                    1 if section.Characteristics & 0x80000000 > 0 else 0, # Writable\n",
    "                ])\n",
    "\n",
    "        return \\\n",
    "            imports, \\\n",
    "            exports, \\\n",
    "            pe.FILE_HEADER.NumberOfSections, \\\n",
    "            pe.OPTIONAL_HEADER.SizeOfCode, \\\n",
    "            pe.OPTIONAL_HEADER.SizeOfImage, \\\n",
    "            pe.OPTIONAL_HEADER.SizeOfStackReserve, \\\n",
    "            pe.OPTIONAL_HEADER.SizeOfStackCommit, \\\n",
    "            pe.OPTIONAL_HEADER.SizeOfHeapReserve, \\\n",
    "            pe.OPTIONAL_HEADER.SizeOfHeapCommit, \\\n",
    "            sections\n",
    "    except:\n",
    "        return    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Shannon Entropy of a File\n",
    "def entropy(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        byteArr = list(f.read())\n",
    "    fileSize = len(byteArr)\n",
    "    freqList = []\n",
    "    for b in range(256):\n",
    "        ctr = 0\n",
    "        for byte in byteArr:\n",
    "            if byte == b:\n",
    "                ctr += 1\n",
    "        freqList.append(float(ctr) / fileSize)\n",
    "    \n",
    "    ent = 0.0\n",
    "    for freq in freqList:\n",
    "        if freq > 0:\n",
    "            ent =  ent + freq * math.log(freq,2)\n",
    "    return -ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-8:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_224702/3117644514.py\", line 5, in ThreadJob\n",
      "TypeError: cannot unpack non-iterable NoneType object\n"
     ]
    }
   ],
   "source": [
    "for i in range(numThreads):\n",
    "    worker = Thread(target=ThreadJob, args=(sampleQueue, writeQueue))\n",
    "    worker.setDaemon(True)\n",
    "    worker.start()\n",
    "\n",
    "with open('samples.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\n",
    "        'index',\n",
    "        'label',\n",
    "        'file_type',\n",
    "        'file_size',\n",
    "        'file_entropy',\n",
    "        'imports',\n",
    "        'exports',\n",
    "        'size_of_image',\n",
    "        'size_of_code',\n",
    "        'size_of_stack_reserve',\n",
    "        'size_of_stack_commit', \n",
    "        'size_of_heap_reserve',\n",
    "        'size_of_heap_commit',\n",
    "        'number_of_sections',\n",
    "        'sections',        \n",
    "    ])\n",
    "\n",
    "    while True:\n",
    "        if writeQueue.empty():\n",
    "            continue\n",
    "\n",
    "        writer.writerow(writeQueue.get())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
